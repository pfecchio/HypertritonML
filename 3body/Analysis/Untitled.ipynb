{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import analysis_utils as au\n",
    "import generalized_analysis as ga\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# avoid pandas warning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb hyperparameters that we are going to tune with bayesia optimization\n",
    "params_range = {\n",
    "    # general parameters\n",
    "    'silent': 0,  # print message (useful to understand what's happening)\n",
    "    'nthread': 4,  # number of available threads\n",
    "    # booster parameters\n",
    "    'eta': [0.05, [0.0001, 0.3]],  # a kind of learning rate\n",
    "    # defines the min sum of weights of all observations required in a child (regularization)\n",
    "    'min_child_weight': [5, [1, 12]],\n",
    "    'max_depth': [8, [2, 20]],  # defines the maximum depth of a single tree (regularization)\n",
    "    'gamma': [0.7, [0, 1.1]],  # specifies the minimum loss reduction required to make a split\n",
    "    'subsample': [0.8, [0.3, 1.]],  # denotes the fraction of observations to be randomly samples for each tree\n",
    "    'colsample_bytree': [0.1, [0.3, 10.]],  # denotes the fraction of columns to be randomly samples for each tree\n",
    "    # 'lambda': [0, [0,10]],  # L2 regularization term on weights\n",
    "    # 'alpha': [0, [0,10]],  # L1 regularization term on weight\n",
    "    # should be used in case of high class imbalance as it helps in faster convergence\n",
    "    'scale_pos_weight': [1., [1., 10.]],\n",
    "    # learning task parameters\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "default_params = {\n",
    "    # general parameters\n",
    "    'silent': 0,  # print message (useful to understand what's happening)\n",
    "    'nthread': 4,  # number of available threads\n",
    "    # booster parameters\n",
    "    'eta': 0.05,\n",
    "    'min_child_weight': 5,\n",
    "    'max_depth': 8,\n",
    "    'gamma': 0.7,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'scale_pos_weight': 1.,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "training_columns = [\n",
    "    'HypCandPt', 'PtDeu', 'PtP', 'PtPi', 'nClsTPCDeu', 'nClsTPCP', 'nClsTPCPi', 'nClsITSDeu', 'nClsITSP',\n",
    "    'nClsITSPi', 'nSigmaTPCDeu', 'nSigmaTPCP', 'nSigmaTPCPi', 'nSigmaTOFDeu', 'nSigmaTOFP', 'nSigmaTOFPi',\n",
    "    'trackChi2Deu', 'trackChi2P', 'trackChi2Pi', 'vertexChi2', 'DCA2xyPrimaryVtxDeu', 'DCAxyPrimaryVtxP',\n",
    "    'DCAxyPrimaryVtxPi', 'DCAzPrimaryVtxDeu', 'DCAzPrimaryVtxP', 'DCAzPrimaryVtxPi', 'DCAPrimaryVtxDeu',\n",
    "    'DCAPrimaryVtxP', 'DCAPrimaryVtxPi', 'DCAxyDecayVtxDeu', 'DCAxyDecayVtxP', 'DCAxyDecayVtxPi', 'DCAzDecayVtxDeu',\n",
    "    'DCAzDecayVtxP', 'DCAzDecayVtxPi', 'DCADecayVtxDeu', 'DCADecayVtxP', 'DCADecayVtxPi', 'TrackDistDeuP',\n",
    "    'TrackDistPPi', 'TrackDistDeuPi', 'CosPA']  # 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = os.environ['HYPERML_TABLES_3']\n",
    "signal_table_path = '{}/HyperTritonTable_19d2.root'.format(table_path)\n",
    "background_table_path = '{}/HyperTritonTable_18q.root'.format(table_path)\n",
    "\n",
    "cent_bins = [[0, 10], [10, 30], [30, 50], [50, 90]]\n",
    "pt_bins = [[1, 2], [2, 3], [3, 4], [4, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = ga.GeneralizedAnalysis(3, signal_table_path, background_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start timer for performance evaluation\n",
    "start_time = time.time()\n",
    "\n",
    "model = analysis.train_test(\n",
    "    training_columns, params_range,\n",
    "    cent_class=1,\n",
    "    bkg_reduct=False, bkg_factor=10, draw=False, optimize=True)\n",
    "\n",
    "print('')\n",
    "print('--- {} minutes ---'.format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
